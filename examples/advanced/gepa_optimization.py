#!/usr/bin/env python3
"""
Advanced DSPy: GEPA (Generative Prompt Auto-optimization) 

Demonstrates:
- Self-reflective prompt improvement
- Iterative optimization with GEPA
- Performance tracking across iterations
- Automatic prompt evolution
- Meta-learning capabilities
"""

import os
import dspy
from dotenv import load_dotenv
from dspy.teleprompt import GEPA
from dspy import Example, Evaluate, metrics
from typing import List, Dict
import json

# Load environment variables
load_dotenv()

class MathWordProblemSolver(dspy.Module):
    """Math word problem solver that can be optimized with GEPA."""
    
    def __init__(self):
        super().__init__()
        self.solve = dspy.ChainOfThought("problem -> solution: str, answer: float")
    
    def forward(self, problem: str):
        """Solve a math word problem."""
        result = self.solve(problem=problem)
        return result

class TextClassifier(dspy.Module):
    """Text classifier for sentiment analysis that can be optimized."""
    
    def __init__(self):
        super().__init__()
        self.classify = dspy.ChainOfThought("text -> sentiment: str, confidence: float")
    
    def forward(self, text: str):
        """Classify text sentiment."""
        result = self.classify(text=text)
        return result

class QAModule(dspy.Module):
    """Question answering module for optimization."""
    
    def __init__(self):
        super().__init__()
        self.answer = dspy.ChainOfThought("context, question -> answer: str")
    
    def forward(self, context: str, question: str):
        """Answer question based on context."""
        result = self.answer(context=context, question=question)
        return result

def create_math_dataset() -> List[Example]:
    """Create a dataset of math word problems for training."""
    problems = [
        {
            "problem": "Sarah has 24 apples. She gives 8 apples to her friend and then buys 15 more. How many apples does she have now?",
            "answer": 31.0
        },
        {
            "problem": "A store sells shirts for $25 each. If John buys 3 shirts and pays with a $100 bill, how much change should he receive?",
            "answer": 25.0
        },
        {
            "problem": "Lisa runs 2.5 miles every day for 6 days. How many total miles does she run?",
            "answer": 15.0
        },
        {
            "problem": "A pizza is cut into 8 slices. If 3 people each eat 2 slices, how many slices are left?",
            "answer": 2.0
        },
        {
            "problem": "Tom saves $50 per month for 8 months. How much money has he saved in total?",
            "answer": 400.0
        },
        {
            "problem": "A rectangular garden is 12 feet long and 8 feet wide. What is its area in square feet?",
            "answer": 96.0
        },
        {
            "problem": "Maria has $120. She spends 1/3 of her money on books and 1/4 on food. How much money does she have left?",
            "answer": 50.0
        },
        {
            "problem": "A train travels 60 miles per hour. How far will it travel in 2.5 hours?",
            "answer": 150.0
        }
    ]
    
    examples = []
    for item in problems:
        example = Example(
            problem=item["problem"],
            answer=item["answer"]
        ).with_inputs("problem")
        examples.append(example)
    
    return examples

def create_sentiment_dataset() -> List[Example]:
    """Create a sentiment analysis dataset."""
    texts = [
        {"text": "I love this product! It's amazing and works perfectly.", "sentiment": "positive"},
        {"text": "This is the worst purchase I've ever made. Complete waste of money.", "sentiment": "negative"},
        {"text": "The item is okay, nothing special but does the job.", "sentiment": "neutral"},
        {"text": "Outstanding quality and excellent customer service! Highly recommend.", "sentiment": "positive"},
        {"text": "Terrible experience. Poor quality and rude staff.", "sentiment": "negative"},
        {"text": "Average product with standard features. Price is reasonable.", "sentiment": "neutral"},
        {"text": "Absolutely fantastic! Exceeded all my expectations.", "sentiment": "positive"},
        {"text": "Disappointing quality for the price. Would not buy again.", "sentiment": "negative"},
    ]
    
    examples = []
    for item in texts:
        example = Example(
            text=item["text"],
            sentiment=item["sentiment"]
        ).with_inputs("text")
        examples.append(example)
    
    return examples

def create_qa_dataset() -> List[Example]:
    """Create a question answering dataset."""
    qa_pairs = [
        {
            "context": "Python is a high-level programming language known for its simplicity and readability. It was created by Guido van Rossum and first released in 1991. Python supports multiple programming paradigms including procedural, object-oriented, and functional programming.",
            "question": "Who created Python?",
            "answer": "Guido van Rossum"
        },
        {
            "context": "Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without explicit programming. Common types include supervised learning, unsupervised learning, and reinforcement learning.",
            "question": "What is machine learning?",
            "answer": "Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without explicit programming"
        },
        {
            "context": "The solar system consists of the Sun and everything that orbits around it, including eight planets, their moons, asteroids, comets, and other celestial bodies. Earth is the third planet from the Sun.",
            "question": "How many planets are in the solar system?",
            "answer": "Eight planets"
        }
    ]
    
    examples = []
    for item in qa_pairs:
        example = Example(
            context=item["context"],
            question=item["question"],
            answer=item["answer"]
        ).with_inputs("context", "question")
        examples.append(example)
    
    return examples

def math_accuracy_metric(prediction, ground_truth):
    """Custom metric for math problems that allows small numerical differences."""
    try:
        # Extract numeric answer from prediction
        pred_answer = float(prediction.answer) if hasattr(prediction, 'answer') else 0
        true_answer = float(ground_truth.answer)
        
        # Allow 1% tolerance for floating point differences
        tolerance = abs(true_answer) * 0.01 + 0.01
        return abs(pred_answer - true_answer) <= tolerance
    except:
        return False

def sentiment_accuracy_metric(prediction, ground_truth):
    """Custom metric for sentiment classification."""
    try:
        pred_sentiment = prediction.sentiment.lower() if hasattr(prediction, 'sentiment') else ""
        true_sentiment = ground_truth.sentiment.lower()
        return pred_sentiment == true_sentiment
    except:
        return False

def run_gepa_optimization(module, dataset, metric, task_name: str, iterations: int = 3):
    """Run GEPA optimization and track performance."""
    print(f"\nüîÑ GEPA Optimization for {task_name}")
    print("-" * 50)
    
    # Split dataset
    train_size = int(len(dataset) * 0.7)
    trainset = dataset[:train_size]
    testset = dataset[train_size:]
    
    print(f"   Training examples: {len(trainset)}")
    print(f"   Test examples: {len(testset)}")
    
    # Baseline performance
    print("\nüìä Baseline Performance:")
    baseline_evaluator = Evaluate(testset, metric=metric)
    baseline_score = baseline_evaluator(module)
    print(f"   Baseline Accuracy: {baseline_score:.2%}")
    
    # Initialize GEPA optimizer
    try:
        gepa_optimizer = GEPA(
            metric=metric,
            breadth=3,  # Number of prompt candidates to try
            depth=iterations  # Number of optimization rounds
        )
        
        print(f"\nüß† Running GEPA Optimization ({iterations} iterations)...")
        
        # Run optimization
        optimized_module = gepa_optimizer.compile(module, trainset=trainset)
        
        # Evaluate optimized module
        print("\nüìà Optimized Performance:")
        optimized_evaluator = Evaluate(testset, metric=metric)
        optimized_score = optimized_evaluator(optimized_module)
        print(f"   Optimized Accuracy: {optimized_score:.2%}")
        
        # Calculate improvement
        improvement = optimized_score - baseline_score
        improvement_percent = (improvement / baseline_score * 100) if baseline_score > 0 else 0
        
        print(f"\nüéØ Optimization Results:")
        print(f"   Improvement: {improvement:.2%}")
        print(f"   Relative Improvement: {improvement_percent:.1f}%")
        
        return {
            "task": task_name,
            "baseline_score": baseline_score,
            "optimized_score": optimized_score,
            "improvement": improvement,
            "improvement_percent": improvement_percent,
            "module": optimized_module
        }
        
    except Exception as e:
        print(f"   ‚ùå GEPA optimization failed: {e}")
        return {
            "task": task_name,
            "baseline_score": baseline_score,
            "error": str(e)
        }

def demonstrate_prompt_evolution(module, example):
    """Show how prompts evolve through GEPA optimization."""
    print(f"\nüîç Prompt Evolution Demo:")
    print("-" * 30)
    
    # Show original prompt behavior
    print("üìù Original Module:")
    try:
        if hasattr(module, 'solve'):
            result = module.solve(problem=example.problem)
        elif hasattr(module, 'classify'):
            result = module.classify(text=example.text)
        elif hasattr(module, 'answer'):
            result = module.answer(context=example.context, question=example.question)
        
        print(f"   Input: {list(example.inputs().values())[0][:60]}...")
        print(f"   Output: {str(result)[:100]}...")
        
    except Exception as e:
        print(f"   Error demonstrating: {e}")

def main():
    """Run GEPA optimization examples."""
    print("üß† DSPy GEPA (Generative Prompt Auto-optimization)")
    print("=" * 60)
    
    # Configure model
    try:
        if os.getenv('OPENAI_API_KEY'):
            dspy.configure(lm=dspy.LM('openai/gpt-4o-mini'))
            print("‚úÖ Using OpenAI GPT-4o-mini")
        else:
            dspy.configure(lm=dspy.LM('ollama_chat/llama3'))
            print("‚úÖ Using Ollama Llama3")
            print("‚ö†Ô∏è  Note: GEPA works best with more capable models")
    except Exception as e:
        print(f"‚ùå Model configuration failed: {e}")
        return
    
    # Create datasets
    math_dataset = create_math_dataset()
    sentiment_dataset = create_sentiment_dataset()
    qa_dataset = create_qa_dataset()
    
    optimization_results = []
    
    # Test 1: Math Word Problems
    print("\n" + "="*60)
    print("üî¢ Testing: Math Word Problem Optimization")
    math_module = MathWordProblemSolver()
    
    # Show example before optimization
    if math_dataset:
        demonstrate_prompt_evolution(math_module, math_dataset[0])
    
    math_result = run_gepa_optimization(
        math_module, math_dataset, math_accuracy_metric, "Math Problems", iterations=2
    )
    optimization_results.append(math_result)
    
    # Test 2: Sentiment Classification
    print("\n" + "="*60)
    print("üòä Testing: Sentiment Classification Optimization")
    sentiment_module = TextClassifier()
    
    if sentiment_dataset:
        demonstrate_prompt_evolution(sentiment_module, sentiment_dataset[0])
    
    sentiment_result = run_gepa_optimization(
        sentiment_module, sentiment_dataset, sentiment_accuracy_metric, "Sentiment Analysis", iterations=2
    )
    optimization_results.append(sentiment_result)
    
    # Test 3: Question Answering (if we have time/resources)
    print("\n" + "="*60)
    print("‚ùì Testing: Question Answering Optimization")
    qa_module = QAModule()
    
    if qa_dataset:
        demonstrate_prompt_evolution(qa_module, qa_dataset[0])
    
    qa_result = run_gepa_optimization(
        qa_module, qa_dataset, metrics.answer_exact_match, "Question Answering", iterations=2
    )
    optimization_results.append(qa_result)
    
    # Summary of all optimizations
    print("\n" + "="*60)
    print("üìä GEPA Optimization Summary")
    print("-" * 60)
    
    successful_optimizations = [r for r in optimization_results if "error" not in r]
    
    if successful_optimizations:
        for result in successful_optimizations:
            task = result["task"]
            baseline = result["baseline_score"]
            optimized = result["optimized_score"]
            improvement = result["improvement_percent"]
            
            print(f"   {task:20s}: {baseline:.1%} ‚Üí {optimized:.1%} ({improvement:+.1f}%)")
        
        avg_improvement = sum(r["improvement_percent"] for r in successful_optimizations) / len(successful_optimizations)
        print(f"\n   Average Improvement: {avg_improvement:.1f}%")
    
    # Failed optimizations
    failed_optimizations = [r for r in optimization_results if "error" in r]
    if failed_optimizations:
        print(f"\n   Failed Optimizations: {len(failed_optimizations)}")
        for result in failed_optimizations:
            print(f"      {result['task']}: {result['error']}")
    
    print(f"\nüéØ Key Insights:")
    print("   ‚úÖ GEPA automatically improves prompts through iteration")
    print("   ‚úÖ Self-reflective optimization reduces manual prompt engineering")
    print("   ‚úÖ Works across different task types and domains")
    print("   ‚ö†Ô∏è  Requires sufficient computational resources")
    print("   ‚ö†Ô∏è  Performance depends on base model capabilities")
    
    print(f"\nüöÄ Production Recommendations:")
    print("   - Use GEPA for high-value, performance-critical tasks")
    print("   - Start with good baseline prompts for better results")
    print("   - Monitor optimization costs and set appropriate budgets")
    print("   - Combine GEPA with other optimization techniques")
    print("   - Cache optimized prompts for reuse")

if __name__ == "__main__":
    main()